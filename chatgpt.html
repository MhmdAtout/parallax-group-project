<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./css/chatgpt.css">
    <title>Chat GPT</title>
</head>
<body>
    <div class="pimg1">
        <div class="ptext">
                <p >ChatGPT</p>
        </div>
    </div>
    <section class="section">
        <div class="pimg5">
                
        </div> 
        <div class="text">  
            <h2> What is ChatGPT?</h2>
            <br>
            <p>    
                Chat GPT (Generative Pre-Trained Transformer) is a type of language model developed by OpenAI. It is designed to generate natural language responses to input text based on a large amount of training data. Chat GPT is an example of a "transformer" model, which means it uses a self-attention mechanism to weigh the importance of different words in a sentence and capture long-range dependencies.
                Chat GPT has been trained on a wide range of text data, including books, news articles, and online forums, which enables it to generate responses that are often indistinguishable from those written by a human. 
            </p> 
        </div>
    </section>
    <div class="pimg2">
    </div> 
    <section >
         <div class="text1">  <h2>How good is ChatGPT, really?</h2>
             <br>
             <p class="text11"> 
                ChatGPT has a few flaws. The answers could be wrong in a number of factual areas. For instance, it might invent false historical accounts and publications or provide incorrect math solutions.
                The knowledge of ChatGPT is still limited to 2021 data, while it might develop in the future. It is believed that ChatGPT would open the door for later, much more advanced AI systems.
                  
            </p>
        </div>
    <div class="pimg3"> 
    </div>
    <section class="section">
        <div class="text">
             <h2>How does ChatGPT work?</h2>
             <br>
             <p>
                The technology underlying GPT-3 seems to be simple. It reacts quickly to your commands, questions, or prompts. As you might think, the technology required to carry this off is much more complicated than it first appears to be.
                To train the model, internet text datasets were employed. More specifically, 300 billion words were provided to the program.
                As a language model, it employs probability to anticipate what the word that comes after a phrase should be. To get to the point where it could do this, the model underwent supervised testing.
                In order to become the ultimate know-it-all, this technology constantly improves its comprehension of prompts and inquiries while making educated guesses about what the next word should be.
             </p>
        </div>
        <div class="pimg4">  
        </div>
    </section>
    <div class="pimg1">    
    </div>
</body>
</html>